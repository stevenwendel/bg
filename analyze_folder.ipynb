{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.neuron import *\n",
    "from src.utils import *\n",
    "from src.constants import * \n",
    "from src.network import *\n",
    "from src.validation import *\n",
    "from src.viz import *\n",
    "from src.genetic_algorithm import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~Check best plot from each pkl file~~\n",
    "# Go through all the pkl files in the data directory and find the dna with the highest dna_score.\n",
    "# Then, print the dna and the dna_score.\n",
    "# Then, run the network with that dna score, print the results (including the new DNA score), and plot the them. \n",
    "# May not work in .ipynb because of multiprocessing.\n",
    "\n",
    "def process_pkl_file(pkl_path):\n",
    "    try:\n",
    "        # Load the pickle file\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Flatten the data structure\n",
    "        flattened_data = []\n",
    "        for generation, runs in data.items():\n",
    "            for run in runs:\n",
    "                if isinstance(run, dict) and 'dna_score' in run:\n",
    "                    flattened_data.append(run)\n",
    "                else:\n",
    "                    print(f\"Unexpected format in file {pkl_path}: {run}\")\n",
    "        \n",
    "        # Find DNA with highest score\n",
    "        best_dna = max(flattened_data, key=lambda x: x['dna_score'])\n",
    "        print(f\"Best DNA: {best_dna}\")\n",
    "        print(f\"Best DNA score: {best_dna['dna_score']}\")\n",
    "        # Get DNA matrix\n",
    "        dna_matrix = load_dna(best_dna['dna'])\n",
    "        \n",
    "        # Prepare network components\n",
    "        all_neurons = create_neurons()\n",
    "        splits, input_waves, alpha_array = create_experiment()\n",
    "        criteria_dict = define_criteria()\n",
    "        max_score = TMAX // BIN_SIZE * len(CRITERIA_NAMES)\n",
    "        \n",
    "        # Evaluate DNA\n",
    "        dna_score, neuron_data = evaluate_dna(\n",
    "            dna_matrix=dna_matrix,\n",
    "            neurons=all_neurons,\n",
    "            alpha_array=alpha_array,\n",
    "            input_waves=input_waves,\n",
    "            criteria=criteria_dict,\n",
    "            curr_dna=best_dna['dna']\n",
    "        )\n",
    "        \n",
    "        total_score = sum(dna_score.values())\n",
    "        \n",
    "        return {\n",
    "            'file': os.path.basename(pkl_path),\n",
    "            'dna': best_dna['dna'],\n",
    "            'scores': dna_score,\n",
    "            'total_score': total_score,\n",
    "            'max_score': max_score,\n",
    "            'neuron_data': neuron_data,\n",
    "            'input_waves': input_waves\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {pkl_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Get all pkl files in data directory\n",
    "    print(\"Starting to process pkl files\")\n",
    "    data_dir = 'data'\n",
    "    pkl_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.pkl')]\n",
    "    \n",
    "    # Process files in parallel\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(process_pkl_file, pkl_files)\n",
    "    \n",
    "    # Filter out None results (files that caused errors)\n",
    "    results = [result for result in results if result is not None]\n",
    "    \n",
    "    # Print results and generate plots for each file\n",
    "    for result in results:\n",
    "        print(f\"\\nResults for {result['file']}:\")\n",
    "        print(f\"    === DNA: {result['dna']}\")\n",
    "        print(f\"    === Control: {result['scores']['control']}/{result['max_score']}\")\n",
    "        print(f\"    === Experimental: {result['scores']['experimental']}/{result['max_score']}\")\n",
    "        print(f\"    === Overall: {result['total_score']}({result['total_score']/(2*result['max_score']):.2%})\")\n",
    "        \n",
    "        # # Plot results\n",
    "        # for condition in ['experimental', 'control']:\n",
    "        #     target_neurons_hist_Vs = np.array([result['neuron_data'][condition][name]['hist_V'] for name in NEURON_NAMES])\n",
    "        #     plot_neurons_interactive(\n",
    "        #         hist_Vs=target_neurons_hist_Vs, \n",
    "        #         neuron_names=NEURON_NAMES, \n",
    "        #         sq_wave=result['input_waves'][0], \n",
    "        #         go_wave=result['input_waves'][1], \n",
    "        #         show_u=False,\n",
    "        #         title=f\"{result['file']} - {condition}\"\n",
    "        #     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the pkl files in the data directory into a single pkl file.\n",
    "\n",
    "def combine_pkl_files(directory, output_file):\n",
    "    combined_data = []\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pkl'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            # Load the pkl file\n",
    "            with open(file_path, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "                \n",
    "                # Add the 'file' key to each entry\n",
    "                for key, entries in data.items():\n",
    "                    for entry in entries:\n",
    "                        entry['file'] = filename\n",
    "                        combined_data.append(entry)\n",
    "\n",
    "    # Save the combined data to a new pkl file\n",
    "    with open(output_file, 'wb') as output:\n",
    "        pickle.dump(combined_data, output)\n",
    "\n",
    "# Usage\n",
    "combine_pkl_files('/Users/stevenwendel/Documents/GitHub/bg/data', 'combined_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
